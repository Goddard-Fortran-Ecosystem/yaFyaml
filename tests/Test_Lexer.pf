module Test_Lexer
   use, intrinsic :: iso_c_binding, only: NL => C_NEW_LINE
   use fy_Lexer
   use fy_TextStream
   use fy_EscapedTextStream
   use fy_Tokens
   use fy_Reader
   use funit
   use fy_TokenVector
   implicit none

contains


   @test
   subroutine test_is_at_document_start()
      type(Lexer) :: lexr

      lexr = Lexer(Reader(TextStream("---")))
      @assertTrue(lexr%is_at_document_boundary('---'))

      lexr = Lexer(Reader(TextStream("- -")))
      @assertFalse(lexr%is_at_document_boundary('---'))

      ! Must start in 0th column
      lexr = Lexer(Reader(TextStream(" ---")))
      @assertFalse(lexr%is_at_document_boundary('---'))

      ! cannot have regular character immediately next
      lexr = Lexer(Reader(TextStream("---a")))
      @assertFalse(lexr%is_at_document_boundary('---'))

   end subroutine test_is_at_document_start


   @test
   subroutine test_is_at_document_end()
      type(Lexer) :: lexr

      lexr = Lexer(Reader(TextStream("...")))
      @assertTrue(lexr%is_at_document_boundary('...'))

      lexr = Lexer(Reader(TextStream(". .")))
      @assertFalse(lexr%is_at_document_boundary('...'))

      ! Must end in 0th column
      lexr = Lexer(Reader(TextStream(" ...")))
      @assertFalse(lexr%is_at_document_boundary('...'))

      ! cannot have regular character immediately next
      lexr = Lexer(Reader(TextStream("...a")))
      @assertFalse(lexr%is_at_document_boundary('...'))

   end subroutine test_is_at_document_end

   @test
   subroutine test_scan_to_next_token()
      type(Lexer) :: lexr

      lexr = Lexer(Reader(TextStream("a")))
      call lexr%scan_to_next_token()
#ifdef __GFORTRAN__
#else
      @assert_that(lexr%peek(), is('a'))
#endif

      lexr = Lexer(Reader(TextStream("b")))
      call lexr%scan_to_next_token()
#ifdef __GFORTRAN__
#else
      @assert_that(lexr%peek(), is('b'))
#endif    
      lexr = Lexer(Reader(TextStream("  b")))
      call lexr%scan_to_next_token()
#ifdef __GFORTRAN__
#else
      @assert_that(lexr%peek(), is('b'))
#endif
      lexr = Lexer(Reader(EscapedTextStream("  \n  b")))
      call lexr%scan_to_next_token()
#ifdef __GFORTRAN__
#else
      @assert_that(lexr%peek(), is('b'))
#endif    
      lexr = Lexer(Reader(EscapedTextStream("  # comment \n  :")))
      call lexr%scan_to_next_token()
#ifdef __GFORTRAN__
#else
      @assert_that(lexr%peek(), is(':'))
#endif
      lexr = Lexer(Reader(EscapedTextStream("  # comment \n  \n# foo  #\n -")))
      call lexr%scan_to_next_token()
#ifdef __GFORTRAN__
#else
      @assert_that(lexr%peek(), is('-'))
#endif
   end subroutine test_scan_to_next_token

   @test
   subroutine test_flow_sequence_end_token()
      type(Lexer) :: lexr
      character(:), allocatable :: id

      lexr = Lexer(Reader(TextStream("]")))

      call lexr%skip_token() ! skip stream start
      associate (token => lexr%get_token())
        id = token%get_id()
#ifdef __GFORTRAN__
#else
        @assert_that(id, is(equal_to(']')))
#endif
      end associate

   end subroutine test_flow_sequence_end_token

   @test
   subroutine test_flow_mapping_end_token()
      type(Lexer) :: lexr
      character(:), allocatable :: id

      lexr = Lexer(Reader(TextStream("}")))

      call lexr%skip_token() ! skip stream start
      associate (token => lexr%get_token())
        id = token%get_id()
#ifdef __GFORTRAN__
#else
        @assert_that(id, is(equal_to(FLOW_MAPPING_END_INDICATOR)))
#endif
      end associate
   end subroutine test_flow_mapping_end_token


   @test
   subroutine test_flow_next_entry()
      type(Lexer) :: lexr
      character(:), allocatable :: id

      lexr = Lexer(Reader(TextStream(",")))

      call lexr%skip_token() ! skip stream start
      associate (token => lexr%get_token())
        id = token%get_id()
#ifdef __GFORTRAN__
#else
        @assert_that(id, is(equal_to(FLOW_NEXT_ENTRY_INDICATOR)))
#endif
      end associate

   end subroutine test_flow_next_entry

   @test
   subroutine test_block_next_entry()
      type(Lexer) :: lexr
      character(:), allocatable :: id

      lexr = Lexer(Reader(TextStream("- a")))

      call lexr%skip_token() ! skip stream start
      associate(token => lexr%get_token())
        id = token%get_id()
        @assertEqual(id, "<block sequence start>")
      end associate

      associate(token => lexr%get_token())
        id = token%get_id()
#ifdef __GFORTRAN__
#else
        @assert_that(id, is(equal_to(BLOCK_NEXT_ENTRY_INDICATOR)))
#endif
      end associate
   end subroutine test_block_next_entry


   @test
   subroutine test_value()
      type(Lexer) :: lexr
      character(:), allocatable :: id

      lexr = Lexer(Reader(TextStream("a:")))

      call lexr%skip_token() ! skip stream start
      call lexr%skip_token() ! skip document start

      associate (token => lexr%get_token())
        id = token%get_id()
#ifdef __GFORTRAN__
#else
        @assert_that(id, is(equal_to(KEY_INDICATOR)))
#endif
      end associate

      call lexr%skip_token()
      associate (token => lexr%get_token()) ! scalar token
        id = token%get_id()
#ifdef __GFORTRAN__
#else
        @assert_that(id, is(equal_to(VALUE_INDICATOR)))
#endif
      end associate
   end subroutine test_value

   @test
   subroutine test_plain_scalar()
      type(Lexer) :: lexr
      character(:), allocatable :: id

      lexr = Lexer(Reader(TextStream("abc d ")))

      call lexr%skip_token() ! skip stream start
      associate(token => lexr%get_token()) ! skip stream start
        id = token%get_id()
        @assert_that(id, is(equal_to('<scalar>')))

        select type (token)
        type is (ScalarToken)
           @assert_that(token%is_plain, is(true()))
#ifdef __GFORTRAN__
#else
           @assert_that(token%value, is(equal_to('abc d')))
#endif
        end select
      end associate

   end subroutine test_plain_scalar


   @test
   subroutine test_is_value()
      type(Lexer) :: lexr
      character(:), allocatable :: id

      ! flow context
      lexr = Lexer(Reader(TextStream("  a : b")))
      call lexr%skip_token() ! skip stream start
      call lexr%skip_token() ! skip block mapping start
      call lexr%skip_token() ! skip key 
      call lexr%skip_token() ! skip scalar "a"

      associate( token => lexr%get_token())
        id = token%get_id()
#ifdef __GFORTRAN__
#else
        @assert_that(id, is(equal_to(':')))
#endif
      end associate

      ! block context - no space after ":"
      lexr = Lexer(Reader(TextStream("{? a : b}")))

      call lexr%skip_token() ! skip stream start
      associate (token => lexr%get_token()) ! "{"
        id = token%get_id()
#ifdef __GFORTRAN__
#else
        @assert_that(id, is(equal_to('{')))
#endif
      end associate

      associate (token => lexr%get_token()) ! key marker
        id = token%get_id()
#ifdef __GFORTRAN__
#else
        @assert_that(id, is(equal_to('?')))
#endif
      end associate

      associate (token => lexr%get_token()) ! a
        id = token%get_id()
#ifdef __GFORTRAN__
#else
        @assert_that(id, is(equal_to('<scalar>')))
#endif
      end associate

      associate (token => lexr%get_token()) ! a
        id = token%get_id()
#ifdef __GFORTRAN__
#else
        @assert_that(id, is(equal_to(':')))
#endif
      end associate

   end subroutine test_is_value

   @test
   subroutine test_is_anchor()
      type(Lexer) :: lexr
      character(:), allocatable :: id

      lexr = Lexer(Reader(TextStream("&anchor")))
      call lexr%skip_token() ! skip stream start

      associate (token => lexr%get_token())
        id = token%get_id()

#ifdef __GFORTRAN__
#else
        @assert_that(id, is(equal_to('<anchor>')))
#endif
      end associate

   end subroutine test_is_anchor


   @test
   subroutine test_is_alias()
      type(Lexer) :: lexr
      character(:), allocatable :: id

      lexr = Lexer(Reader(TextStream("*alias")))
      call lexr%skip_token() ! skip stream start

      associate(token => lexr%get_token())
        id = token%get_id()

#ifdef __GFORTRAN__
#else
        @assert_that(id, is(equal_to('<alias>')))
#endif
      end associate

   end subroutine test_is_alias


end module Test_Lexer

